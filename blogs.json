{"status":"ok","feed":{"url":"https://medium.com/feed/@faizan-ali","title":"Stories by Faizan Safdar Ali on Medium","link":"https://medium.com/@faizan-ali?source=rss-694dc83417cb------2","author":"","description":"Stories by Faizan Safdar Ali on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/0*v6pGdCvW-2UTypsU"},"items":[{"title":"Building a Baby Demand Prediction using Node.js, Machine Learning And ChatGPT","pubDate":"2023-04-03 22:19:12","link":"https://medium.com/@faizan-ali/building-a-baby-demand-prediction-using-node-js-machine-learning-and-chatgpt-4486b651a345?source=rss-694dc83417cb------2","guid":"https://medium.com/p/4486b651a345","author":"Faizan Safdar Ali","thumbnail":"https://cdn-images-1.medium.com/max/922/1*I1RtRos6Uo6SLGJGXyFV4w.png","description":"\n<h3>Building a Baby Demand Prediction Application using Node.js, Machine Learning And\u00a0ChatGPT</h3>\n<h3>Preface:</h3>\n<p>I became father of a beautiful baby girl last month. If you are a parent, you would vouch on the fact that how little time a newborn allows you to have for yourself. It has been a journey figuring out what your baby needs. This gave me an idea of why not take help from machines (as it is cool now a days)? It started from a joke with my wife \u201cshould we ask ChatGPT to figure what our daughter wants?\u201d but later I got invested a little too much. I did not start with aim to write an article on this, but the finding I had pushed me into doing this. Moreover, I might write more follow up articles on this topic later\u00a0on.</p>\n<h3>Reader\u2019s Notes:</h3>\n<ol>\n<li>This article is not technichally intense, it was just a side-side-side project I did in how much little time my little one allowed me to have. I am using basic Node interfaces and CNN models to have a proof of concept kind of\u00a0project.</li>\n<li>As I had a very little time, I aimed at doing everything using ChatGPT. Most of the code was written on advised by ChatGPT. Moreover, other than first two sections of this article, most of the article is generated through\u00a0ChatGPT.</li>\n<li>Because most of the work was done by ChatGPT, there are several places where the project is using suboptimal approaches (one of the downside of ChatGPT). Additionally, there are abundant parts of the system that can be improved.</li>\n<li>I will mention all the prompts, replies and the changes I made to make this\u00a0project.</li>\n<li>The code contains a lot of magic numbers. More research can be done for better optimization.</li>\n</ol>\n<h3>Introduction</h3>\n<p>As a new parent, it can be difficult to determine what your baby needs when they cry. While experience can help you identify common causes, every baby is different and it can take time to get a sense of what your baby is trying to communicate. However, with advancements in technology, it is possible to build a system that can help you identify your baby\u2019s needs based on their\u00a0cry.</p>\n<p>In this article, we will explore how to build a Baby Cry Detector using Node.js and Machine Learning. I will start by how I set up a basic web application that allows users to upload a photo of their baby and select the reason for their cry. I used these images to Then, I will integrate a Machine Learning model to analyze the uploaded image and provide a prediction of the baby\u2019s needs based on their\u00a0cry.</p>\n<h3>System Design:</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/922/1*I1RtRos6Uo6SLGJGXyFV4w.png\"><figcaption>System architecture. Generated by ChatGPT using Graphviz. I requested for system design diagrams using tools suggested by ChatGPT, and requested modifications to the diagrams with additional components and colors. I had to do changes as it stopped understanding me.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/297/1*h2XKrdUcTbJeF3oZ4VhSpw.png\"><figcaption>Storage Component in detail. Again generated by\u00a0ChatGPT</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/458/1*cUr3dC-GwihrP5DM8DP1PA.png\"><figcaption>Prediction Component in detail. Again generated by\u00a0ChatGPT</figcaption></figure><h3>Setting up the Web Application</h3>\n<p>First, I created a basic web application using Node.js and Express to handle file uploads. I used `express-generator` to scaffold the\u00a0project:</p>\n<pre>$&gt; express baby-cry</pre>\n<p>This created a basic folder structure for my project. The logic is in JavaScript (ES5) whereas views are generated in JADE. This is by\u00a0default.</p>\n<p>Moving forward, I started asking ChatGPT the questions:</p>\n<blockquote>Prompt: write simple jade file that allows file upload using a button in\u00a0express</blockquote>\n<p>Jade:</p>\n<pre>html<br>  head<br>    title File Upload Example<br>  body<br>    h1 File Upload Example<br>    form(action='/upload', method='post', enctype='multipart/form-data')<br>      input(type='file', name='file')<br>      button(type='submit') Upload</pre>\n<p>JS:</p>\n<pre>const express = require('express');<br>const multer = require('multer');<br><br>const app = express();<br><br>// Configure multer to store uploaded files in the 'uploads' directory<br>const upload = multer({ dest: 'uploads/' });<br><br>// Display the file upload form<br>app.get('/', (req, res) =&gt; {<br>  res.render('upload-form');<br>});<br><br>// Handle the file upload<br>app.post('/upload', upload.single('file'), (req, res) =&gt; {<br>  // The uploaded file is stored in req.file<br>  console.log(req.file);<br>  res.send('File uploaded successfully');<br>});<br><br>app.listen(3000, () =&gt; {<br>  console.log('Server started on port 3000');<br>});</pre>\n<blockquote>Prompt: Great, now add a drop down to the form that has three values \u201cHunger\u201d, \u201cDiaper Change\u201d, \u201cDiscomfort\u201d. These values determine where to store the\u00a0image.</blockquote>\n<p>Jade:</p>\n<pre>doctype html<br>html<br>  head<br>    title File Upload Form<br>  body<br>    h1 File Upload Form<br>    form(action='/upload', method='post', enctype='multipart/form-data')<br>      label(for='file') Select a file:<br>      input(type='file', name='file', id='file')<br>      br<br>      label(for='option') Select an option:<br>      select(name='option', id='option')<br>        each option in options<br>          option(value=option)= option<br>      br<br>      input(type='submit', value='Upload')</pre>\n<p>JS:</p>\n<pre>// Configure multer to store uploaded files in the 'uploads' directory<br>const storage = multer.diskStorage({<br>  destination: (req, file, cb) =&gt; {<br><br>    const option = req.body.option;<br><br>    const uploadDir = path.join(__dirname, '/ml-module/data/uploads');<br>    const destDir = path.join(uploadDir, option);<br><br>    if (!fs.existsSync(destDir)) {<br>      fs.mkdirSync(destDir, { recursive: true });<br>    }<br><br>    cb(null, destDir);<br>  },<br>  filename: (req, file, cb) =&gt; {<br>    cb(null, file.originalname);<br>  }<br>});<br>const upload = multer({ storage });</pre>\n<p>This gives me basic application. Lastly, I asked to add styles and make it responsive.</p>\n<blockquote>Prompt: Add little styles to beautify. Make app responsive.</blockquote>\n<p>Jade:</p>\n<pre>doctype html<br>html<br>  head<br>    title File Upload Form<br>    meta(name='viewport', content='width=device-width, initial-scale=1.0')<br>    style.<br>      body {<br>        font-family: Arial, sans-serif;<br>        font-size: 14px;<br>        margin: 0;<br>        padding: 0;<br>      }<br><br>      h1 {<br>        text-align: center;<br>        margin-top: 24px;<br>      }<br><br>      form {<br>        margin-top: 24px;<br>        display: flex;<br>        flex-direction: column;<br>        align-items: center;<br>        justify-content: center;<br>      }<br><br>      label {<br>        display: block;<br>        margin-bottom: 12px;<br>        font-weight: bold;<br>      }<br><br>      input[type=\"file\"], select {<br>        margin-bottom: 12px;<br>      }<br><br>      input[type=\"submit\"] {<br>        background-color: #4CAF50;<br>        color: white;<br>        font-weight: bold;<br>        padding: 12px 24px;<br>        border: none;<br>        border-radius: 4px;<br>        cursor: pointer;<br>      }<br><br>      input[type=\"submit\"]:hover {<br>        background-color: #3e8e41;<br>      }<br><br>      /* Responsive styles */<br>      @media only screen and (max-width: 767px) {<br>        h1 {<br>          font-size: 24px;<br>        }<br><br>        form {<br>          width: 90%;<br>        }<br><br>        input[type=\"submit\"] {<br>          font-size: 16px;<br>          padding: 8px 16px;<br>        }<br>      }<br><br>      @media only screen and (min-width: 768px) {<br>        h1 {<br>          font-size: 36px;<br>        }<br><br>        form {<br>          width: 50%;<br>        }<br><br>        input[type=\"submit\"] {<br>          font-size: 18px;<br>        }<br>      }<br>  body<br>    h1 File Upload Form<br>    form(action='/upload', method='post', enctype='multipart/form-data')<br>      label(for='file') Select a file:<br>      input(type='file', name='file', id='file')<br>      br<br>      label(for='option') Select an option:<br>      select(name='option', id='option')<br>        each option in options<br>          option(value=option)= option<br>      br<br>      input(type='submit', value='Upload')</pre>\n<p>Later, it automatically started generating CSS file, that I added to the project\u00a0<a href=\"https://github.com/faiziali98/baby-cry-demand-detection\">here</a>.</p>\n<p>The script uses Multer to handle file uploads and saved the uploaded files to a specified directory based on the selected reason for the baby\u2019s\u00a0cry.</p>\n<p>The created form in Jade allowed users to upload a photo of their baby and select the reason for their cry. I also added a button to submit the\u00a0form.</p>\n<p>The logic to be able to predict the mood of the baby was written by myself. I just had to copy paste ChatGPT code and link it to cropper (details\u00a0later).</p>\n<pre>app.post('/upload', upload.single('file'), async (req, res) =&gt; {<br>  imageCroper(req.file.path);<br><br>  res.send(`<br>    &lt;p style=\"font-size: 24px; font-weight: bold; color: #333;\"&gt;File uploaded!&lt;/p&gt;<br>    &lt;button style=\"background-color: #4CAF50; color: white; padding: 12px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; margin-top: 16px;\" onclick=\"window.location.href='/'\"&gt;Back to Main&lt;/button&gt;<br>  `);<br>});</pre>\n<p>The ` res.send` was generated by ChatGPT, the prompt was <strong>\u201cReturn HTML from the handler\u201d.</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/351/1*rffGgIJ_5t-jOduuDYB7SA.png\"><figcaption>Resultant application. Not bad at\u00a0all!!</figcaption></figure><p>There were other promts such as \u201cmake this centered\u201d, \u201cmake that bold\u201d that I have skipped for sake of frugality. Overall, this works great. I had to adjust code and structure it (ChatGPT decreased reusability) that I will talk about\u00a0later.</p>\n<h3>Machine Learning Components:</h3>\n<p>There are mainly three ML components:</p>\n<ol>\n<li>ML Model.</li>\n<li>Predictor.</li>\n<li>Face Detector.</li>\n</ol>\n<p><strong>ML Model:</strong></p>\n<p>Next, I asked ChatGPT to create model for demand detection. It used TensorFlow.js to build a Convolutional Neural Network (CNN) model that can analyze the uploaded images and provide a prediction.</p>\n<p>Yesss! AI generating AI. Reminds me of South Indian Movie\u00a0\u201cRobot\u201d.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/550/1*P7AAfLQZ38l9EZ1vnKTTOQ.jpeg\"><figcaption>AI Robot created multiple of its own\u00a0kind.</figcaption></figure><blockquote>Prompt: Write an ML model in Node that takes an image of a new born and predicts what it wants. Save model to be used for prediction later.</blockquote>\n<p>JS:</p>\n<pre>const tf = require('@tensorflow/tfjs-node');<br>const { inputShape, numClasses } = require('./constants');<br><br>// Define the CNN architecture<br>const model = tf.sequential();<br>model.add(tf.layers.conv2d({<br>  filters: 32,<br>  kernelSize: 3,<br>  activation: 'relu',<br>  inputShape: inputShape<br>}));<br>model.add(tf.layers.maxPooling2d({<br>  poolSize: 2,<br>  strides: 2<br>}));<br>model.add(tf.layers.conv2d({<br>  filters: 64,<br>  kernelSize: 3,<br>  activation: 'relu'<br>}));<br>model.add(tf.layers.maxPooling2d({<br>  poolSize: 2,<br>  strides: 2<br>}));<br>model.add(tf.layers.conv2d({<br>  filters: 128,<br>  kernelSize: 3,<br>  activation: 'relu'<br>}));<br>model.add(tf.layers.maxPooling2d({<br>  poolSize: 2,<br>  strides: 2<br>}));<br>model.add(tf.layers.flatten());<br>model.add(tf.layers.dense({<br>  units: 128,<br>  activation: 'relu'<br>}));<br>model.add(tf.layers.dense({<br>  units: numClasses,<br>  activation: 'softmax'<br>}));<br>model.compile({<br>  loss: 'categoricalCrossentropy',<br>  optimizer: tf.train.adam(),<br>  metrics: ['accuracy']<br>});<br><br>module.exports = model;</pre>\n<p>It also generated structure to train the model. I changed it drastically hence skipping it here. One learning was that ChatGPT provided following code:</p>\n<pre>model.fit(trainData, {<br>  epochs: numEpochs,<br>  batchSize: batchSize,<br>  stepsPerEpoch: stepsPerEpoch,<br>  validationData: validationData,<br>  validationSteps: validationSteps<br>}).then(() =&gt; {<br>  // Save the trained model to a file<br>  model.save('file://../trained-models/model-1a');<br>});</pre>\n<p>Here `trainData` is a generator and `fit` function does not work with generators, the correct function to use here is `fitDataset`. I assume ChatGPT did not have knowledge of it as it is a recent\u00a0change.</p>\n<p>Finally, I created <a href=\"https://github.com/faiziali98/baby-cry-demand-detection/blob/main/ml-module/scripts/train-model.js\">train-model.js</a> file that can be run to train model and saves it for later use of prediction.</p>\n<p><strong>Predictor:</strong></p>\n<blockquote>Prompt: Now use this model to predict on new\u00a0image.</blockquote>\n<p>Result:</p>\n<pre>const tf = require('@tensorflow/tfjs-node');<br>const fs = require('fs');<br>const path = require('path');<br><br>// Update the following variables with the path to your trained model and input image file<br>const modelPath = './ml-module/trained-models/model-1a/model.json';<br><br>const predictor = async (imagePath) =&gt; {<br><br>    // Load the trained model<br>    const model = await tf.loadLayersModel(`file://${modelPath}`);<br><br>    // Load the input image<br>    const image = fs.readFileSync(imagePath);<br>    const tensor = tf.node.decodeImage(image, 3);<br>    const resized = tf.image.resizeBilinear(tensor, [200, 200]).toFloat();<br>    const normalized = tf.div(resized, tf.scalar(255));<br>    const batched = normalized.expandDims(0);<br><br>    // Make a prediction on the input image<br>    const prediction = model.predict(batched);<br><br>    // Convert the prediction to an array<br>    const predictionArray = prediction.arraySync()[0];<br><br>    // Update the following array with your own classes<br>    const classes = [\"Change\", \"Comfort\", \"Food\"];<br><br>    // Find the index of the highest probability class<br>    const maxIndex = predictionArray.indexOf(Math.max(...predictionArray));<br><br>    // Print the predicted class<br>    return `The newborn wants ${classes[maxIndex]}.`;<br>};<br><br>module.exports = predictor;</pre>\n<p>This predictor was then used in\u00a0app.js.</p>\n<pre>app.post('/check', check_upload.single('file'), async (req, res) =&gt; {<br>  const file = req.file;<br>  await imageCroper(file.path);<br>  const prediction = await predictor(file.path);<br><br>  res.send(`<br>    &lt;p style=\"font-size: 24px; font-weight: bold; color: #333;\"&gt;${prediction}&lt;/p&gt;<br>    &lt;button style=\"background-color: #4CAF50; color: white; padding: 12px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; margin-top: 16px;\" onclick=\"window.location.href='/'\"&gt;Back to Main&lt;/button&gt;<br>  `);<br>})</pre>\n<p>Here is our first room for improvement. Currently, I save the new image, crop it and then send it for prediction. This can be done without save. Although, in hind side, it gives me opportunity to collect more data to train\u00a0on.</p>\n<p>The model gave <strong>60% accuracy and 57%</strong> precision value (after some preprocessing discussed later). Not bad at all! I want to state here that I had small set of data and all images were of my daughter (therefore, it could not detect my wife\u2019s moods I still had to do it my self). A diverse dataset can be used to improve this\u00a0work.</p>\n<p><strong>Face Cropper:</strong></p>\n<p>Earlier, I was getting really bad performance. I instantly realized that when I am reducing the size of the images (I had to do that as my laptop is a very basic one), it is cropping parts of images that do not have faces in them. So I asked\u00a0chatGPT:</p>\n<blockquote>Prompt: Write a code in Node that takes image as input and crop it to 200 by 200 around the\u00a0face.</blockquote>\n<p>Result:</p>\n<pre>const faceapi = require('face-api.js');<br>const sharp = require('sharp');<br>const fs = require('fs');<br><br>// Load face detection model<br>Promise.all([<br>  faceapi.nets.tinyFaceDetector.loadFromDisk('./models'),<br>  faceapi.nets.faceLandmark68Net.loadFromDisk('./models')<br>]).then(detectFace);<br><br>async function detectFace() {<br>  // Load input image<br>  const inputImg = await sharp('./input.jpg');<br><br>  // Detect face in image<br>  const faceDetectionOptions = new faceapi.TinyFaceDetectorOptions({ <br>    inputSize: 320, <br>    scoreThreshold: 0.5 <br>  });<br>  const faceDetectionResult = await faceapi.detectSingleFace(inputImg.toBuffer(), faceDetectionOptions).withFaceLandmarks();<br><br>  if (!faceDetectionResult) {<br>    console.log('No face detected in input image');<br>    return;<br>  }<br><br>  // Get face bounding box<br>  const faceBoundingBox = faceDetectionResult.detection.box;<br><br>  // Crop image around face<br>  const croppedImg = await inputImg<br>    .extract({<br>      left: Math.max(0, faceBoundingBox.x - faceBoundingBox.width * 0.5),<br>      top: Math.max(0, faceBoundingBox.y - faceBoundingBox.height * 0.5),<br>      width: faceBoundingBox.width * 2,<br>      height: faceBoundingBox.height * 2<br>    })<br>    .resize(200, 200, { fit: 'cover' });<br><br>  // Save cropped image<br>  await croppedImg.toFile('./output.jpg');<br><br>  console.log('Image cropped and saved to output.jpg');<br>}</pre>\n<p>Wow! Problem solved? Not at all. There were large amount of tweeks I had to do as this code is not compatible with lated Node version. The shown code is updated code. I am skipping details as they are in my Git repo and I mostly did them without asking ChatGPT and by reading documentation and github\u00a0README.</p>\n<p>The result was that I could crop the face of the\u00a0baby</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/200/1*db4IxBNZHISK9DiPGFjthA.jpeg\"><figcaption>Resultant image. Not my baby\u00a0though!!</figcaption></figure><p>The same cropper is used for both training and prediction purposes. There can be better alternatives such as openCV that can be used for this but I stuck with ChatGPT\u2019s suggestion.</p>\n<h3>Experimentation:</h3>\n<p>I used my laptop as my local server. I accessed it using my phone\u00a0through:</p>\n<pre>http://laptop_ip:3000</pre>\n<p>I also asked my wife to take many pictures and upload them. It was\u00a0fun.</p>\n<p>After that, I trained the\u00a0model.</p>\n<p>Lastly, I tested it by uploading new picture and getting prediction</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/183/1*KTRVTW04PRMcvky512DaEg.png\"><figcaption>Yayy!!! Now I\u00a0know!</figcaption></figure><h3>Learning:</h3>\n<p><strong>About Application:</strong></p>\n<ol>\n<li>Node can be a powerful framework to create such applications.</li>\n<li>AI is future, it has potential to solve day to day\u00a0issues.</li>\n</ol>\n<p><strong>About ChatGPT:</strong></p>\n<p><strong>Pros:</strong></p>\n<ol>\n<li>It reduced a lot of research work by providing answers on a single platform. It saved me huge amount of time I would have wasted on Googling\u00a0stuff.</li>\n<li>ChatGPT is very powerful when it is asked already answered questions. For example, face cropping was super straight forward as there is library that provides examples. GPT just copied\u00a0them.</li>\n<li>GPT can be utilized to get initital ideas on almost anything. Coding, diagrams, writing\u00a0etc.</li>\n</ol>\n<p><strong>Cons:</strong></p>\n<ol>\n<li>Although ChatGPT can create small pieces, its still far from generating complex\u00a0systems.</li>\n<li>I have seen people creating games from it, but all of them are well known games code to which is readily available. It gives random (mostly wrong) code for new problems.</li>\n<li>ChatGPT sometimes provide partial answers meaning it will stop in the middle of the code. This is maybe because of free version word generation limit. The problem is, it starts from beginning everytime I regenerate the answer (work around, copy the code, paste it in prompt, ask GPT to complete\u00a0it).</li>\n<li>ChatGPT changes the logic of the program when asked to add/update a specific part of initially generated code. Now this is fine if we completely use the code generated by ChatGPT, but if you have build custom logic on top of that, it becomes difficult to get further assistance from\u00a0ChatGPT.</li>\n<li>It is sometime very hard to convey your idea to ChatGPT. As english (yes I wrote it in smalls to emphisise my point) is not my first language, I had hard time communicating with\u00a0ChatGPT.</li>\n</ol>\n<h3>Future Work:</h3>\n<p>In future, there can be follow up articles on following points. Do comment if there is something else interesting you think\u00a0of!</p>\n<ol>\n<li>Improving AI\u00a0model.</li>\n<li>Getting more\u00a0data.</li>\n<li>Improving code structure.</li>\n<li>Making the system more scalable.</li>\n<li>Exploring more depth of\u00a0ChatGPT.</li>\n</ol>\n<h3>Conclusion</h3>\n<p>In this article, we have explored how to build a Baby Cry Detector using Node.js and Machine Learning. We started by setting up a basic web application that allows users to upload a photo of their baby and select the reason for their cry. Then, we integrated a Machine Learning model to analyze the uploaded image and provide a prediction of the baby\u2019s needs based on their\u00a0cry.</p>\n<p>This application can be useful for new parents who may be struggling to identify the needs of their baby based on their cry. While the accuracy of the model may not be perfect, it can provide some helpful guidance and potentially reduce the stress and anxiety associated with caring for a\u00a0newborn.</p>\n<p>Overall, this project demonstrates the potential of Machine Learning in solving real-world problems and improving the quality of life for\u00a0people.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4486b651a345\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<h3>Building a Baby Demand Prediction Application using Node.js, Machine Learning And\u00a0ChatGPT</h3>\n<h3>Preface:</h3>\n<p>I became father of a beautiful baby girl last month. If you are a parent, you would vouch on the fact that how little time a newborn allows you to have for yourself. It has been a journey figuring out what your baby needs. This gave me an idea of why not take help from machines (as it is cool now a days)? It started from a joke with my wife \u201cshould we ask ChatGPT to figure what our daughter wants?\u201d but later I got invested a little too much. I did not start with aim to write an article on this, but the finding I had pushed me into doing this. Moreover, I might write more follow up articles on this topic later\u00a0on.</p>\n<h3>Reader\u2019s Notes:</h3>\n<ol>\n<li>This article is not technichally intense, it was just a side-side-side project I did in how much little time my little one allowed me to have. I am using basic Node interfaces and CNN models to have a proof of concept kind of\u00a0project.</li>\n<li>As I had a very little time, I aimed at doing everything using ChatGPT. Most of the code was written on advised by ChatGPT. Moreover, other than first two sections of this article, most of the article is generated through\u00a0ChatGPT.</li>\n<li>Because most of the work was done by ChatGPT, there are several places where the project is using suboptimal approaches (one of the downside of ChatGPT). Additionally, there are abundant parts of the system that can be improved.</li>\n<li>I will mention all the prompts, replies and the changes I made to make this\u00a0project.</li>\n<li>The code contains a lot of magic numbers. More research can be done for better optimization.</li>\n</ol>\n<h3>Introduction</h3>\n<p>As a new parent, it can be difficult to determine what your baby needs when they cry. While experience can help you identify common causes, every baby is different and it can take time to get a sense of what your baby is trying to communicate. However, with advancements in technology, it is possible to build a system that can help you identify your baby\u2019s needs based on their\u00a0cry.</p>\n<p>In this article, we will explore how to build a Baby Cry Detector using Node.js and Machine Learning. I will start by how I set up a basic web application that allows users to upload a photo of their baby and select the reason for their cry. I used these images to Then, I will integrate a Machine Learning model to analyze the uploaded image and provide a prediction of the baby\u2019s needs based on their\u00a0cry.</p>\n<h3>System Design:</h3>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/922/1*I1RtRos6Uo6SLGJGXyFV4w.png\"><figcaption>System architecture. Generated by ChatGPT using Graphviz. I requested for system design diagrams using tools suggested by ChatGPT, and requested modifications to the diagrams with additional components and colors. I had to do changes as it stopped understanding me.</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/297/1*h2XKrdUcTbJeF3oZ4VhSpw.png\"><figcaption>Storage Component in detail. Again generated by\u00a0ChatGPT</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/458/1*cUr3dC-GwihrP5DM8DP1PA.png\"><figcaption>Prediction Component in detail. Again generated by\u00a0ChatGPT</figcaption></figure><h3>Setting up the Web Application</h3>\n<p>First, I created a basic web application using Node.js and Express to handle file uploads. I used `express-generator` to scaffold the\u00a0project:</p>\n<pre>$&gt; express baby-cry</pre>\n<p>This created a basic folder structure for my project. The logic is in JavaScript (ES5) whereas views are generated in JADE. This is by\u00a0default.</p>\n<p>Moving forward, I started asking ChatGPT the questions:</p>\n<blockquote>Prompt: write simple jade file that allows file upload using a button in\u00a0express</blockquote>\n<p>Jade:</p>\n<pre>html<br>  head<br>    title File Upload Example<br>  body<br>    h1 File Upload Example<br>    form(action='/upload', method='post', enctype='multipart/form-data')<br>      input(type='file', name='file')<br>      button(type='submit') Upload</pre>\n<p>JS:</p>\n<pre>const express = require('express');<br>const multer = require('multer');<br><br>const app = express();<br><br>// Configure multer to store uploaded files in the 'uploads' directory<br>const upload = multer({ dest: 'uploads/' });<br><br>// Display the file upload form<br>app.get('/', (req, res) =&gt; {<br>  res.render('upload-form');<br>});<br><br>// Handle the file upload<br>app.post('/upload', upload.single('file'), (req, res) =&gt; {<br>  // The uploaded file is stored in req.file<br>  console.log(req.file);<br>  res.send('File uploaded successfully');<br>});<br><br>app.listen(3000, () =&gt; {<br>  console.log('Server started on port 3000');<br>});</pre>\n<blockquote>Prompt: Great, now add a drop down to the form that has three values \u201cHunger\u201d, \u201cDiaper Change\u201d, \u201cDiscomfort\u201d. These values determine where to store the\u00a0image.</blockquote>\n<p>Jade:</p>\n<pre>doctype html<br>html<br>  head<br>    title File Upload Form<br>  body<br>    h1 File Upload Form<br>    form(action='/upload', method='post', enctype='multipart/form-data')<br>      label(for='file') Select a file:<br>      input(type='file', name='file', id='file')<br>      br<br>      label(for='option') Select an option:<br>      select(name='option', id='option')<br>        each option in options<br>          option(value=option)= option<br>      br<br>      input(type='submit', value='Upload')</pre>\n<p>JS:</p>\n<pre>// Configure multer to store uploaded files in the 'uploads' directory<br>const storage = multer.diskStorage({<br>  destination: (req, file, cb) =&gt; {<br><br>    const option = req.body.option;<br><br>    const uploadDir = path.join(__dirname, '/ml-module/data/uploads');<br>    const destDir = path.join(uploadDir, option);<br><br>    if (!fs.existsSync(destDir)) {<br>      fs.mkdirSync(destDir, { recursive: true });<br>    }<br><br>    cb(null, destDir);<br>  },<br>  filename: (req, file, cb) =&gt; {<br>    cb(null, file.originalname);<br>  }<br>});<br>const upload = multer({ storage });</pre>\n<p>This gives me basic application. Lastly, I asked to add styles and make it responsive.</p>\n<blockquote>Prompt: Add little styles to beautify. Make app responsive.</blockquote>\n<p>Jade:</p>\n<pre>doctype html<br>html<br>  head<br>    title File Upload Form<br>    meta(name='viewport', content='width=device-width, initial-scale=1.0')<br>    style.<br>      body {<br>        font-family: Arial, sans-serif;<br>        font-size: 14px;<br>        margin: 0;<br>        padding: 0;<br>      }<br><br>      h1 {<br>        text-align: center;<br>        margin-top: 24px;<br>      }<br><br>      form {<br>        margin-top: 24px;<br>        display: flex;<br>        flex-direction: column;<br>        align-items: center;<br>        justify-content: center;<br>      }<br><br>      label {<br>        display: block;<br>        margin-bottom: 12px;<br>        font-weight: bold;<br>      }<br><br>      input[type=\"file\"], select {<br>        margin-bottom: 12px;<br>      }<br><br>      input[type=\"submit\"] {<br>        background-color: #4CAF50;<br>        color: white;<br>        font-weight: bold;<br>        padding: 12px 24px;<br>        border: none;<br>        border-radius: 4px;<br>        cursor: pointer;<br>      }<br><br>      input[type=\"submit\"]:hover {<br>        background-color: #3e8e41;<br>      }<br><br>      /* Responsive styles */<br>      @media only screen and (max-width: 767px) {<br>        h1 {<br>          font-size: 24px;<br>        }<br><br>        form {<br>          width: 90%;<br>        }<br><br>        input[type=\"submit\"] {<br>          font-size: 16px;<br>          padding: 8px 16px;<br>        }<br>      }<br><br>      @media only screen and (min-width: 768px) {<br>        h1 {<br>          font-size: 36px;<br>        }<br><br>        form {<br>          width: 50%;<br>        }<br><br>        input[type=\"submit\"] {<br>          font-size: 18px;<br>        }<br>      }<br>  body<br>    h1 File Upload Form<br>    form(action='/upload', method='post', enctype='multipart/form-data')<br>      label(for='file') Select a file:<br>      input(type='file', name='file', id='file')<br>      br<br>      label(for='option') Select an option:<br>      select(name='option', id='option')<br>        each option in options<br>          option(value=option)= option<br>      br<br>      input(type='submit', value='Upload')</pre>\n<p>Later, it automatically started generating CSS file, that I added to the project\u00a0<a href=\"https://github.com/faiziali98/baby-cry-demand-detection\">here</a>.</p>\n<p>The script uses Multer to handle file uploads and saved the uploaded files to a specified directory based on the selected reason for the baby\u2019s\u00a0cry.</p>\n<p>The created form in Jade allowed users to upload a photo of their baby and select the reason for their cry. I also added a button to submit the\u00a0form.</p>\n<p>The logic to be able to predict the mood of the baby was written by myself. I just had to copy paste ChatGPT code and link it to cropper (details\u00a0later).</p>\n<pre>app.post('/upload', upload.single('file'), async (req, res) =&gt; {<br>  imageCroper(req.file.path);<br><br>  res.send(`<br>    &lt;p style=\"font-size: 24px; font-weight: bold; color: #333;\"&gt;File uploaded!&lt;/p&gt;<br>    &lt;button style=\"background-color: #4CAF50; color: white; padding: 12px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; margin-top: 16px;\" onclick=\"window.location.href='/'\"&gt;Back to Main&lt;/button&gt;<br>  `);<br>});</pre>\n<p>The ` res.send` was generated by ChatGPT, the prompt was <strong>\u201cReturn HTML from the handler\u201d.</strong></p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/351/1*rffGgIJ_5t-jOduuDYB7SA.png\"><figcaption>Resultant application. Not bad at\u00a0all!!</figcaption></figure><p>There were other promts such as \u201cmake this centered\u201d, \u201cmake that bold\u201d that I have skipped for sake of frugality. Overall, this works great. I had to adjust code and structure it (ChatGPT decreased reusability) that I will talk about\u00a0later.</p>\n<h3>Machine Learning Components:</h3>\n<p>There are mainly three ML components:</p>\n<ol>\n<li>ML Model.</li>\n<li>Predictor.</li>\n<li>Face Detector.</li>\n</ol>\n<p><strong>ML Model:</strong></p>\n<p>Next, I asked ChatGPT to create model for demand detection. It used TensorFlow.js to build a Convolutional Neural Network (CNN) model that can analyze the uploaded images and provide a prediction.</p>\n<p>Yesss! AI generating AI. Reminds me of South Indian Movie\u00a0\u201cRobot\u201d.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/550/1*P7AAfLQZ38l9EZ1vnKTTOQ.jpeg\"><figcaption>AI Robot created multiple of its own\u00a0kind.</figcaption></figure><blockquote>Prompt: Write an ML model in Node that takes an image of a new born and predicts what it wants. Save model to be used for prediction later.</blockquote>\n<p>JS:</p>\n<pre>const tf = require('@tensorflow/tfjs-node');<br>const { inputShape, numClasses } = require('./constants');<br><br>// Define the CNN architecture<br>const model = tf.sequential();<br>model.add(tf.layers.conv2d({<br>  filters: 32,<br>  kernelSize: 3,<br>  activation: 'relu',<br>  inputShape: inputShape<br>}));<br>model.add(tf.layers.maxPooling2d({<br>  poolSize: 2,<br>  strides: 2<br>}));<br>model.add(tf.layers.conv2d({<br>  filters: 64,<br>  kernelSize: 3,<br>  activation: 'relu'<br>}));<br>model.add(tf.layers.maxPooling2d({<br>  poolSize: 2,<br>  strides: 2<br>}));<br>model.add(tf.layers.conv2d({<br>  filters: 128,<br>  kernelSize: 3,<br>  activation: 'relu'<br>}));<br>model.add(tf.layers.maxPooling2d({<br>  poolSize: 2,<br>  strides: 2<br>}));<br>model.add(tf.layers.flatten());<br>model.add(tf.layers.dense({<br>  units: 128,<br>  activation: 'relu'<br>}));<br>model.add(tf.layers.dense({<br>  units: numClasses,<br>  activation: 'softmax'<br>}));<br>model.compile({<br>  loss: 'categoricalCrossentropy',<br>  optimizer: tf.train.adam(),<br>  metrics: ['accuracy']<br>});<br><br>module.exports = model;</pre>\n<p>It also generated structure to train the model. I changed it drastically hence skipping it here. One learning was that ChatGPT provided following code:</p>\n<pre>model.fit(trainData, {<br>  epochs: numEpochs,<br>  batchSize: batchSize,<br>  stepsPerEpoch: stepsPerEpoch,<br>  validationData: validationData,<br>  validationSteps: validationSteps<br>}).then(() =&gt; {<br>  // Save the trained model to a file<br>  model.save('file://../trained-models/model-1a');<br>});</pre>\n<p>Here `trainData` is a generator and `fit` function does not work with generators, the correct function to use here is `fitDataset`. I assume ChatGPT did not have knowledge of it as it is a recent\u00a0change.</p>\n<p>Finally, I created <a href=\"https://github.com/faiziali98/baby-cry-demand-detection/blob/main/ml-module/scripts/train-model.js\">train-model.js</a> file that can be run to train model and saves it for later use of prediction.</p>\n<p><strong>Predictor:</strong></p>\n<blockquote>Prompt: Now use this model to predict on new\u00a0image.</blockquote>\n<p>Result:</p>\n<pre>const tf = require('@tensorflow/tfjs-node');<br>const fs = require('fs');<br>const path = require('path');<br><br>// Update the following variables with the path to your trained model and input image file<br>const modelPath = './ml-module/trained-models/model-1a/model.json';<br><br>const predictor = async (imagePath) =&gt; {<br><br>    // Load the trained model<br>    const model = await tf.loadLayersModel(`file://${modelPath}`);<br><br>    // Load the input image<br>    const image = fs.readFileSync(imagePath);<br>    const tensor = tf.node.decodeImage(image, 3);<br>    const resized = tf.image.resizeBilinear(tensor, [200, 200]).toFloat();<br>    const normalized = tf.div(resized, tf.scalar(255));<br>    const batched = normalized.expandDims(0);<br><br>    // Make a prediction on the input image<br>    const prediction = model.predict(batched);<br><br>    // Convert the prediction to an array<br>    const predictionArray = prediction.arraySync()[0];<br><br>    // Update the following array with your own classes<br>    const classes = [\"Change\", \"Comfort\", \"Food\"];<br><br>    // Find the index of the highest probability class<br>    const maxIndex = predictionArray.indexOf(Math.max(...predictionArray));<br><br>    // Print the predicted class<br>    return `The newborn wants ${classes[maxIndex]}.`;<br>};<br><br>module.exports = predictor;</pre>\n<p>This predictor was then used in\u00a0app.js.</p>\n<pre>app.post('/check', check_upload.single('file'), async (req, res) =&gt; {<br>  const file = req.file;<br>  await imageCroper(file.path);<br>  const prediction = await predictor(file.path);<br><br>  res.send(`<br>    &lt;p style=\"font-size: 24px; font-weight: bold; color: #333;\"&gt;${prediction}&lt;/p&gt;<br>    &lt;button style=\"background-color: #4CAF50; color: white; padding: 12px 20px; border: none; border-radius: 4px; cursor: pointer; font-size: 16px; margin-top: 16px;\" onclick=\"window.location.href='/'\"&gt;Back to Main&lt;/button&gt;<br>  `);<br>})</pre>\n<p>Here is our first room for improvement. Currently, I save the new image, crop it and then send it for prediction. This can be done without save. Although, in hind side, it gives me opportunity to collect more data to train\u00a0on.</p>\n<p>The model gave <strong>60% accuracy and 57%</strong> precision value (after some preprocessing discussed later). Not bad at all! I want to state here that I had small set of data and all images were of my daughter (therefore, it could not detect my wife\u2019s moods I still had to do it my self). A diverse dataset can be used to improve this\u00a0work.</p>\n<p><strong>Face Cropper:</strong></p>\n<p>Earlier, I was getting really bad performance. I instantly realized that when I am reducing the size of the images (I had to do that as my laptop is a very basic one), it is cropping parts of images that do not have faces in them. So I asked\u00a0chatGPT:</p>\n<blockquote>Prompt: Write a code in Node that takes image as input and crop it to 200 by 200 around the\u00a0face.</blockquote>\n<p>Result:</p>\n<pre>const faceapi = require('face-api.js');<br>const sharp = require('sharp');<br>const fs = require('fs');<br><br>// Load face detection model<br>Promise.all([<br>  faceapi.nets.tinyFaceDetector.loadFromDisk('./models'),<br>  faceapi.nets.faceLandmark68Net.loadFromDisk('./models')<br>]).then(detectFace);<br><br>async function detectFace() {<br>  // Load input image<br>  const inputImg = await sharp('./input.jpg');<br><br>  // Detect face in image<br>  const faceDetectionOptions = new faceapi.TinyFaceDetectorOptions({ <br>    inputSize: 320, <br>    scoreThreshold: 0.5 <br>  });<br>  const faceDetectionResult = await faceapi.detectSingleFace(inputImg.toBuffer(), faceDetectionOptions).withFaceLandmarks();<br><br>  if (!faceDetectionResult) {<br>    console.log('No face detected in input image');<br>    return;<br>  }<br><br>  // Get face bounding box<br>  const faceBoundingBox = faceDetectionResult.detection.box;<br><br>  // Crop image around face<br>  const croppedImg = await inputImg<br>    .extract({<br>      left: Math.max(0, faceBoundingBox.x - faceBoundingBox.width * 0.5),<br>      top: Math.max(0, faceBoundingBox.y - faceBoundingBox.height * 0.5),<br>      width: faceBoundingBox.width * 2,<br>      height: faceBoundingBox.height * 2<br>    })<br>    .resize(200, 200, { fit: 'cover' });<br><br>  // Save cropped image<br>  await croppedImg.toFile('./output.jpg');<br><br>  console.log('Image cropped and saved to output.jpg');<br>}</pre>\n<p>Wow! Problem solved? Not at all. There were large amount of tweeks I had to do as this code is not compatible with lated Node version. The shown code is updated code. I am skipping details as they are in my Git repo and I mostly did them without asking ChatGPT and by reading documentation and github\u00a0README.</p>\n<p>The result was that I could crop the face of the\u00a0baby</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/200/1*db4IxBNZHISK9DiPGFjthA.jpeg\"><figcaption>Resultant image. Not my baby\u00a0though!!</figcaption></figure><p>The same cropper is used for both training and prediction purposes. There can be better alternatives such as openCV that can be used for this but I stuck with ChatGPT\u2019s suggestion.</p>\n<h3>Experimentation:</h3>\n<p>I used my laptop as my local server. I accessed it using my phone\u00a0through:</p>\n<pre>http://laptop_ip:3000</pre>\n<p>I also asked my wife to take many pictures and upload them. It was\u00a0fun.</p>\n<p>After that, I trained the\u00a0model.</p>\n<p>Lastly, I tested it by uploading new picture and getting prediction</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/183/1*KTRVTW04PRMcvky512DaEg.png\"><figcaption>Yayy!!! Now I\u00a0know!</figcaption></figure><h3>Learning:</h3>\n<p><strong>About Application:</strong></p>\n<ol>\n<li>Node can be a powerful framework to create such applications.</li>\n<li>AI is future, it has potential to solve day to day\u00a0issues.</li>\n</ol>\n<p><strong>About ChatGPT:</strong></p>\n<p><strong>Pros:</strong></p>\n<ol>\n<li>It reduced a lot of research work by providing answers on a single platform. It saved me huge amount of time I would have wasted on Googling\u00a0stuff.</li>\n<li>ChatGPT is very powerful when it is asked already answered questions. For example, face cropping was super straight forward as there is library that provides examples. GPT just copied\u00a0them.</li>\n<li>GPT can be utilized to get initital ideas on almost anything. Coding, diagrams, writing\u00a0etc.</li>\n</ol>\n<p><strong>Cons:</strong></p>\n<ol>\n<li>Although ChatGPT can create small pieces, its still far from generating complex\u00a0systems.</li>\n<li>I have seen people creating games from it, but all of them are well known games code to which is readily available. It gives random (mostly wrong) code for new problems.</li>\n<li>ChatGPT sometimes provide partial answers meaning it will stop in the middle of the code. This is maybe because of free version word generation limit. The problem is, it starts from beginning everytime I regenerate the answer (work around, copy the code, paste it in prompt, ask GPT to complete\u00a0it).</li>\n<li>ChatGPT changes the logic of the program when asked to add/update a specific part of initially generated code. Now this is fine if we completely use the code generated by ChatGPT, but if you have build custom logic on top of that, it becomes difficult to get further assistance from\u00a0ChatGPT.</li>\n<li>It is sometime very hard to convey your idea to ChatGPT. As english (yes I wrote it in smalls to emphisise my point) is not my first language, I had hard time communicating with\u00a0ChatGPT.</li>\n</ol>\n<h3>Future Work:</h3>\n<p>In future, there can be follow up articles on following points. Do comment if there is something else interesting you think\u00a0of!</p>\n<ol>\n<li>Improving AI\u00a0model.</li>\n<li>Getting more\u00a0data.</li>\n<li>Improving code structure.</li>\n<li>Making the system more scalable.</li>\n<li>Exploring more depth of\u00a0ChatGPT.</li>\n</ol>\n<h3>Conclusion</h3>\n<p>In this article, we have explored how to build a Baby Cry Detector using Node.js and Machine Learning. We started by setting up a basic web application that allows users to upload a photo of their baby and select the reason for their cry. Then, we integrated a Machine Learning model to analyze the uploaded image and provide a prediction of the baby\u2019s needs based on their\u00a0cry.</p>\n<p>This application can be useful for new parents who may be struggling to identify the needs of their baby based on their cry. While the accuracy of the model may not be perfect, it can provide some helpful guidance and potentially reduce the stress and anxiety associated with caring for a\u00a0newborn.</p>\n<p>Overall, this project demonstrates the potential of Machine Learning in solving real-world problems and improving the quality of life for\u00a0people.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4486b651a345\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["ai","node","face-recognition","design","chatgpt"]},{"title":"Create Forms With React Hook Form (RTL) and Validation Using Yup in React Native","pubDate":"2021-11-29 04:37:43","link":"https://medium.com/@faizan-ali/create-forms-with-react-hook-form-rtl-and-validation-using-yup-in-react-native-39d4a8d90b26?source=rss-694dc83417cb------2","guid":"https://medium.com/p/39d4a8d90b26","author":"Faizan Safdar Ali","thumbnail":"https://cdn-images-1.medium.com/max/1024/0*cq7iXBAaNn4jDWcp.png","description":"\n<p>React Native is a JavaScript-based open-source UI software framework created by Meta Platforms to create cross-platform applications. The overall architecture of React Native is very much similar to React but with syntactical differences. You can read <a href=\"https://madhurshanisivan.medium.com/basics-of-react-native-4844747b47c1\">a basic overview of React Native</a> before reading this article. In this article, we will see how we can create forms using RTL and add validations to them using Yup in React\u00a0Native.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*cq7iXBAaNn4jDWcp.png\"><figcaption><a href=\"https://www.futuremind.com/blog/pros-and-cons-react-native-and-native-apps\">https://www.futuremind.com/blog/pros-and-cons-react-native-and-native-apps</a></figcaption></figure><p>Forms are used to get data from the user while using the application. Login forms are a very common example that can be found in most applications nowadays. Usually, a login form takes the password and username/email as input. In most situations, developers introduce validations over these input fields to get the desired type of input from the user. For example, the user should always input a valid email address. In React Native, a custom solution would require state management and custom validations to handle such situations that can be messy and might not be optimal. Hence, using form creation and validation libraries is a better option here. Moving forward, we will use RTL and Yup for creating a form in React Native application.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*u-8R_fijS10SjXB9.jpg\"></figure><h3>Introduction:</h3>\n<p>RTL: <a href=\"https://github.com/testing-library/react-testing-library\">React Testing Library</a> builds on top of DOM Testing Library by adding APIs for working with React components.</p>\n<p>Yup: <a href=\"https://www.npmjs.com/package/yup\">Yup is a JavaScript</a> schema builder for value parsing and validation. Define a schema, transform a value to match, validate the shape of an existing value, or both. Yup schema is extremely expressive and allows modeling complex, interdependent validations, or value transformations.</p>\n<h3>Getting Started</h3>\n<p>I will be using the simple React Native repository and third-party styling library <strong>Tailwind CSS</strong>. The choice is completely yours to prefer whichever library you are comfortable with. I am also using <strong>npm</strong> instead of <strong>yarn</strong> as react-native does not have support for <strong>yarn PnP</strong>. Go ahead and install the React Hook Form using the below\u00a0command.</p>\n<p>npm install --save react-hook-form</p>\n<p>Also install yup\u00a0using:</p>\n<p>npm install --save\u00a0yup</p>\n<p>We will also require yup resolver to translate the schema\u00a0later:</p>\n<p>npm install --save @hookform/resolvers</p>\n<h3>Writing Code</h3>\n<p>We will create a simple form for the user with the following fields:</p>\n<ul>\n<li>\n<strong>password</strong>\u200a\u2014\u200a{ required: true\u00a0,rules: { minLength: 6, maxLength: 50}}</li>\n<li>\n<strong>Email</strong>\u200a\u2014\u200a{required: true, rules: Should have proper\u00a0format}</li>\n</ul>\n<a href=\"https://medium.com/media/ddc77d2a424c30c0fe862923b9b38701/href\">https://medium.com/media/ddc77d2a424c30c0fe862923b9b38701/href</a><p>In this code, we are simply creating a simple form named LoginScreen with TextInputs and a button. This is exported and can be used in the App.ts\u00a0file.</p>\n<h3>Introducing RTL to the\u00a0Code:</h3>\n<p>Now let's add React Testing Library to\u00a0this.</p>\n<a href=\"https://medium.com/media/c96c509e69c347c7fc1859069bf6f4a7/href\">https://medium.com/media/c96c509e69c347c7fc1859069bf6f4a7/href</a><p>Here, we are simply adding a Controller wrapper around TextField. The controller is received from useForm the hook that actually handles inputs and submission later. handleSubmit is the function that does that for us. It takes a function that is run every time a form is submitted. handleSubmit is provoked from the button we have added to the\u00a0form.</p>\n<h3><strong>Form Validation using\u00a0Yup:</strong></h3>\n<p>Now we will use the Yup library to validate the\u00a0form:</p>\n<a href=\"https://medium.com/media/8272bffd94265f50b4f6397ba8202221/href\">https://medium.com/media/8272bffd94265f50b4f6397ba8202221/href</a><p>The last part is to add Yup essentials to do validation. We have imported two new libraries here on lines 5 and 6. Then we create our schema on lines 8\u201311. Let's explain that in a little\u00a0detail:</p>\n<p><strong>email:</strong> <strong>yup.string().email().required().label(\u2018E-mail\u2019) </strong>here we say that an email is a required field that should be a string and a valid email <strong>(string(), and email()). We also add a label to\u00a0it.</strong></p>\n<p><strong>password: yup.string().required().min(6).max(50).label(\u2018Password\u2019) </strong>here only extra addition is min and max that define min length and max length allowed in the password.</p>\n<p>Now that we have defined our schema, we just have to add a resolver to the RTL form. That is done by using <strong>yupResolver </strong>for optional prop <strong>resolver</strong> of <strong>useForm. </strong>Now every time the form is submitted, a resolver will run over it. If the validation fails, the error will be returned in the <strong>errors</strong> variable defined at <strong>line\u00a017</strong>.</p>\n<h3>Final Showdown:</h3>\n<p>At this point, we are ready to see if the form works. Just try to submit the form with different inputs.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/724/1*a5L_Qc-84N34B-fkvq9GRw.png\"><figcaption>Empty fields</figcaption></figure><p>And if we use illegal inputs for\u00a0fields:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/726/1*ZpfiTleq_zAYN6GZwSlM0Q.png\"><figcaption>Illegal inputs</figcaption></figure><p>As we can see the error is shown with respect to the labels that we added in the previous sections.</p>\n<h3>Conclusion:</h3>\n<p>There are many ways to create forms in React Native but RTL with Yup creates form in concise manner with less and manageable code. This article can be used as a tutorial to create different forms using Yup and\u00a0RTL.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=39d4a8d90b26\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>React Native is a JavaScript-based open-source UI software framework created by Meta Platforms to create cross-platform applications. The overall architecture of React Native is very much similar to React but with syntactical differences. You can read <a href=\"https://madhurshanisivan.medium.com/basics-of-react-native-4844747b47c1\">a basic overview of React Native</a> before reading this article. In this article, we will see how we can create forms using RTL and add validations to them using Yup in React\u00a0Native.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*cq7iXBAaNn4jDWcp.png\"><figcaption><a href=\"https://www.futuremind.com/blog/pros-and-cons-react-native-and-native-apps\">https://www.futuremind.com/blog/pros-and-cons-react-native-and-native-apps</a></figcaption></figure><p>Forms are used to get data from the user while using the application. Login forms are a very common example that can be found in most applications nowadays. Usually, a login form takes the password and username/email as input. In most situations, developers introduce validations over these input fields to get the desired type of input from the user. For example, the user should always input a valid email address. In React Native, a custom solution would require state management and custom validations to handle such situations that can be messy and might not be optimal. Hence, using form creation and validation libraries is a better option here. Moving forward, we will use RTL and Yup for creating a form in React Native application.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*u-8R_fijS10SjXB9.jpg\"></figure><h3>Introduction:</h3>\n<p>RTL: <a href=\"https://github.com/testing-library/react-testing-library\">React Testing Library</a> builds on top of DOM Testing Library by adding APIs for working with React components.</p>\n<p>Yup: <a href=\"https://www.npmjs.com/package/yup\">Yup is a JavaScript</a> schema builder for value parsing and validation. Define a schema, transform a value to match, validate the shape of an existing value, or both. Yup schema is extremely expressive and allows modeling complex, interdependent validations, or value transformations.</p>\n<h3>Getting Started</h3>\n<p>I will be using the simple React Native repository and third-party styling library <strong>Tailwind CSS</strong>. The choice is completely yours to prefer whichever library you are comfortable with. I am also using <strong>npm</strong> instead of <strong>yarn</strong> as react-native does not have support for <strong>yarn PnP</strong>. Go ahead and install the React Hook Form using the below\u00a0command.</p>\n<p>npm install --save react-hook-form</p>\n<p>Also install yup\u00a0using:</p>\n<p>npm install --save\u00a0yup</p>\n<p>We will also require yup resolver to translate the schema\u00a0later:</p>\n<p>npm install --save @hookform/resolvers</p>\n<h3>Writing Code</h3>\n<p>We will create a simple form for the user with the following fields:</p>\n<ul>\n<li>\n<strong>password</strong>\u200a\u2014\u200a{ required: true\u00a0,rules: { minLength: 6, maxLength: 50}}</li>\n<li>\n<strong>Email</strong>\u200a\u2014\u200a{required: true, rules: Should have proper\u00a0format}</li>\n</ul>\n<a href=\"https://medium.com/media/ddc77d2a424c30c0fe862923b9b38701/href\">https://medium.com/media/ddc77d2a424c30c0fe862923b9b38701/href</a><p>In this code, we are simply creating a simple form named LoginScreen with TextInputs and a button. This is exported and can be used in the App.ts\u00a0file.</p>\n<h3>Introducing RTL to the\u00a0Code:</h3>\n<p>Now let's add React Testing Library to\u00a0this.</p>\n<a href=\"https://medium.com/media/c96c509e69c347c7fc1859069bf6f4a7/href\">https://medium.com/media/c96c509e69c347c7fc1859069bf6f4a7/href</a><p>Here, we are simply adding a Controller wrapper around TextField. The controller is received from useForm the hook that actually handles inputs and submission later. handleSubmit is the function that does that for us. It takes a function that is run every time a form is submitted. handleSubmit is provoked from the button we have added to the\u00a0form.</p>\n<h3><strong>Form Validation using\u00a0Yup:</strong></h3>\n<p>Now we will use the Yup library to validate the\u00a0form:</p>\n<a href=\"https://medium.com/media/8272bffd94265f50b4f6397ba8202221/href\">https://medium.com/media/8272bffd94265f50b4f6397ba8202221/href</a><p>The last part is to add Yup essentials to do validation. We have imported two new libraries here on lines 5 and 6. Then we create our schema on lines 8\u201311. Let's explain that in a little\u00a0detail:</p>\n<p><strong>email:</strong> <strong>yup.string().email().required().label(\u2018E-mail\u2019) </strong>here we say that an email is a required field that should be a string and a valid email <strong>(string(), and email()). We also add a label to\u00a0it.</strong></p>\n<p><strong>password: yup.string().required().min(6).max(50).label(\u2018Password\u2019) </strong>here only extra addition is min and max that define min length and max length allowed in the password.</p>\n<p>Now that we have defined our schema, we just have to add a resolver to the RTL form. That is done by using <strong>yupResolver </strong>for optional prop <strong>resolver</strong> of <strong>useForm. </strong>Now every time the form is submitted, a resolver will run over it. If the validation fails, the error will be returned in the <strong>errors</strong> variable defined at <strong>line\u00a017</strong>.</p>\n<h3>Final Showdown:</h3>\n<p>At this point, we are ready to see if the form works. Just try to submit the form with different inputs.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/724/1*a5L_Qc-84N34B-fkvq9GRw.png\"><figcaption>Empty fields</figcaption></figure><p>And if we use illegal inputs for\u00a0fields:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/726/1*ZpfiTleq_zAYN6GZwSlM0Q.png\"><figcaption>Illegal inputs</figcaption></figure><p>As we can see the error is shown with respect to the labels that we added in the previous sections.</p>\n<h3>Conclusion:</h3>\n<p>There are many ways to create forms in React Native but RTL with Yup creates form in concise manner with less and manageable code. This article can be used as a tutorial to create different forms using Yup and\u00a0RTL.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=39d4a8d90b26\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["cross-platform","yup","react-native","forms","react-testing-library"]},{"title":"Run Android Application On Emulator and Create a build\u200a\u2014\u200aReact Native","pubDate":"2021-11-24 02:57:09","link":"https://medium.com/@faizan-ali/run-android-application-on-emulator-and-create-a-build-react-native-10e34ef52eb0?source=rss-694dc83417cb------2","guid":"https://medium.com/p/10e34ef52eb0","author":"Faizan Safdar Ali","thumbnail":"https://cdn-images-1.medium.com/max/612/0*VgwLaJXlpaEx917N","description":"\n<h3>Run Android Application On Emulator and Create a build\u200a\u2014\u200aReact\u00a0Native</h3>\n<p>After banging my head against the wall and desperately crying for help over Google, I was finally able to run my React Native application over an android emulator and was able to create a build for Android as well. This article is very helpful for the developers who are either new to the technology or are stuck at a similar type of problem. For those who already are comfortable and bug-free so far, this article is a lesson for you guys as well. Enjoy\u00a0reading.</p>\n<pre>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+<br>| System: Mac OS<br>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+<br>| Tech: React Native<br>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+<br>| Node Version: 15.0.2<br>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/612/0*VgwLaJXlpaEx917N\"><figcaption><a href=\"https://www.istockphoto.com/photos/banging-your-head-against-a-wall\">https://www.istockphoto.com/photos/banging-your-head-against-a-wall</a></figcaption></figure><p>Recently, my company decided to change the technology from Flutter to React Native. Regardless of the fact that Flutter is more famous nowadays, this decision was made on the basis that React Native is an older technology and has a larger community. This implied that there will be more help from open-source discussions and community boards. Little did we know how wrong was this assumption.</p>\n<p>Once the MVP for the application was developed, we jumped right into taking iOS and Android releases live on the respective stores. This worked like a charm for iOS but when it came to Android, there was a storm of bugs and errors that came our way. <strong>Now, these bugs might be common and easily resolvable for a professional Android developer, but for the team that is doing Mobile dev for the first time and that too with React Native, these bugs were as hard as climbing Mount Everest.</strong> Yes, you heard it right, this was our Everest!!</p>\n<p>Two of my teammates started looking into these bugs and tried solving them. After spending a full working day, there was still no progress (they literally were stuck with the very first bug). I decided to lead the team from the front and took upon this task. I sat down with my laptop and made my mind to get up only after I resolve this issue (and that\u2019s what I did in the end, and my wife is still mad at me for that\u00a0:P).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/460/0*vnFw15XWmnOOc8Su\"><figcaption><a href=\"http://sarahaslanifar.com/leadership-vs-management/\">http://sarahaslanifar.com/leadership-vs-management/</a></figcaption></figure><p>Let's jump the guns and enlist my learnings through this experience. I will connect them further along the road as\u00a0well.</p>\n<ol>\n<li>Always trust the documentation. No matter what the community developers are saying, prioritize documentation\u2019s opinions before\u00a0theirs.</li>\n<li>Always run sample code and read it before trying to figure out the solution yourself. L<strong>ook at every\u00a0file!</strong>\n</li>\n<li>If it is working with sample code, it should work with your code as\u00a0well.</li>\n<li>Rather than looking for answers over Google, try to look for other people\u2019s code and see why their code is working. Point number 3 goes with this as\u00a0well.</li>\n<li>The problem might not be in the code, system settings can be\u00a0false.</li>\n<li>Pay a closer look at what is going on, even if you do not understand it in the beginning, you will be able to do that in a\u00a0while.</li>\n<li>Improve your debugging skills and be\u00a0patient.</li>\n<li>Elimination is one of the most helpful debugging techniques.</li>\n</ol>\n<p>Now lets talk about the issues. The very first error that we got\u00a0was:</p>\n<pre>Android Studio \u2014 Unrecognized VM option \u2018MaxPermSize=256m\u2019</pre>\n<p>This is a very known problem with many different answers to the questions. One most obvious answer\u00a0was</p>\n<pre>cd android<br>./gradlew clean<br>react-native run-android</pre>\n<p>What it does is it resets everything and builds the Gradle from scratch. This comes with different variations. Some say to remove\u00a0.gradle and\u00a0.build folders as well. This was a solution to many others but it was not the case with us as we were wrongly doing one very basic step. Another answer that we commonly found\u00a0was:</p>\n<p>\u201c Open the gradle.properties file and remove MaxPremSize as this is not compatible with the latest\u00a0JDK.\u201d</p>\n<p>Now, this partially resolved the issue but created another\u00a0one.</p>\n<pre>Task :expo-modules-core:compileDebugKotlin FAILED react native</pre>\n<p>Many answers to this as well but the most common were to clean the build or to update the <em>android/build.gradle</em> file.</p>\n<blockquote>My thoughts are this is a versioning issue. I solved this by changing the versions of buildTools, compileSdk and targetSdk.</blockquote>\n<blockquote>Go to your android/build.gradle file and change the following values:</blockquote>\n<blockquote>buildToolsVersion = \"29.0.3\" to buildToolsVersion =\u00a0\"30.0.0\"</blockquote>\n<blockquote>compileSdkVersion = 29 to compileSdkVersion =\u00a030</blockquote>\n<blockquote>targetSdkVersion = 29 to targetSdkVersion =\u00a030</blockquote>\n<p>Above is one of the most liked answers I found on StackOverflow.</p>\n<p>None of these solutions worked and finally, I decided to read the <em>documentation</em>. <a href=\"https://reactnative.dev/docs/0.64/environment-setup\">There</a>, I saw that React Native requires the Android 10 (Q) SDK in particular with buildToolsVersion = \"29.0.2\". Moreover, it requires JDK version 11. I grabbed my head in despair and laughed at my stupidity. I looked at my system settings and found that I was using JDK 17 along with SDK 31.0.0. This covers my points 1,3 and 5. <strong>The community was saying there is no need to downgrade, but it only worked once that was\u00a0done.</strong></p>\n<p>So far I had not used sample codes, but soon that was about to change. Once I was done with this, I got stuck into another\u00a0problem.</p>\n<pre>Execution failed for task ':app:compileDebugJavaWithJavac'. react-native.</pre>\n<p>Now what was that all about? I was confused and Googled the query. The same cleaning answer topped the chart again along with some other hacks for\u00a0example:</p>\n<blockquote>So, inspect you node_modules folder, look for react-native folder and look for a folder with a number, that numbers are react-native version. For me it\u2019s 0.58.3 then update <strong>android/app/build.gradle</strong>:</blockquote>\n<blockquote>implementation \"com.facebook.react:react-native:0.58.3\"</blockquote>\n<p>What it means is that we have to specify the exact react-native version to get it working. For me, that was not the\u00a0case.</p>\n<p>I took a step back and downloaded the sample code. I tried running it and it worked how it should. There were no issues at all. That proved that my system has accurate settings and is ready to go. I looked at other people's codes and they were working fine as well. I saw their Gradle files and found no difference there as well. So what does that mean? There is some issue with just my\u00a0code.</p>\n<p>Upon looking at the logs again, I saw that the issue was in generated:</p>\n<pre>android/app/build/generated/rncli/src/main/java/com/facebook/react/PackageList.java</pre>\n<p>This file creates a list of all imports that are required to run the application. The problem was that there were two imports with the same name. In my case it\u00a0was</p>\n<pre>import <em>com.reactnativecommunity.cookies.CookieManagerPackage</em>;</pre>\n<p>Why was that happening, I did not know at that time. But this was the only culprit to be seen. So I started eliminating every package from package.json the file. At last, I found the issue. There were two imports in the JSON\u00a0file</p>\n<pre>react-native-cookies/cookies<br>@react-native-cookies/cookies</pre>\n<p>Now both of them were trying to import CookieManagerPackage and hence Java was not able to compile the code. This was not an issue with iOS and we assumed that this will not cause an issue with Android as\u00a0well.</p>\n<p>Once this was done, our application was running on Emulator just fine. The last issue was when we tried to make the release. The community said there is no need to sign the Android APK for debugging, but that was not the case. Even if you are not releasing it on App Store, you will have to sign it to run it on a real device. Follow the steps\u00a0here:</p>\n<p><a href=\"https://reactnative.dev/docs/signed-apk-android\">Publishing to Google Play Store \u00b7 React Native</a></p>\n<p>This takes us to points 2, 4, 6, 7, 8. Before going for the blind search on Google, you should try to read the documentation and other code examples. Usually, the answers are closer than we think. Also, if the documentation is giving instructions, follow that before following other people\u2019s opinions. They might be using a hack that does not work for everyone.</p>\n<p>I found a very nice meme that summarizes our actions as developers on the daily\u00a0basis.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*F0fV-wyPtO2RP1O374zipA.png\"></figure><p>In the end, I would just like to emphasize the importance of reading documentation and developing strong debugging skills. This article can be used as a guide to run Android Applications on emulators or to create a build when working with React\u00a0Native.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=10e34ef52eb0\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<h3>Run Android Application On Emulator and Create a build\u200a\u2014\u200aReact\u00a0Native</h3>\n<p>After banging my head against the wall and desperately crying for help over Google, I was finally able to run my React Native application over an android emulator and was able to create a build for Android as well. This article is very helpful for the developers who are either new to the technology or are stuck at a similar type of problem. For those who already are comfortable and bug-free so far, this article is a lesson for you guys as well. Enjoy\u00a0reading.</p>\n<pre>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+<br>| System: Mac OS<br>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+<br>| Tech: React Native<br>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+<br>| Node Version: 15.0.2<br>+ \u2014 \u2014 \u2014 \u2014 \u2014 -+ \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 + \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 \u2014 -+</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/612/0*VgwLaJXlpaEx917N\"><figcaption><a href=\"https://www.istockphoto.com/photos/banging-your-head-against-a-wall\">https://www.istockphoto.com/photos/banging-your-head-against-a-wall</a></figcaption></figure><p>Recently, my company decided to change the technology from Flutter to React Native. Regardless of the fact that Flutter is more famous nowadays, this decision was made on the basis that React Native is an older technology and has a larger community. This implied that there will be more help from open-source discussions and community boards. Little did we know how wrong was this assumption.</p>\n<p>Once the MVP for the application was developed, we jumped right into taking iOS and Android releases live on the respective stores. This worked like a charm for iOS but when it came to Android, there was a storm of bugs and errors that came our way. <strong>Now, these bugs might be common and easily resolvable for a professional Android developer, but for the team that is doing Mobile dev for the first time and that too with React Native, these bugs were as hard as climbing Mount Everest.</strong> Yes, you heard it right, this was our Everest!!</p>\n<p>Two of my teammates started looking into these bugs and tried solving them. After spending a full working day, there was still no progress (they literally were stuck with the very first bug). I decided to lead the team from the front and took upon this task. I sat down with my laptop and made my mind to get up only after I resolve this issue (and that\u2019s what I did in the end, and my wife is still mad at me for that\u00a0:P).</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/460/0*vnFw15XWmnOOc8Su\"><figcaption><a href=\"http://sarahaslanifar.com/leadership-vs-management/\">http://sarahaslanifar.com/leadership-vs-management/</a></figcaption></figure><p>Let's jump the guns and enlist my learnings through this experience. I will connect them further along the road as\u00a0well.</p>\n<ol>\n<li>Always trust the documentation. No matter what the community developers are saying, prioritize documentation\u2019s opinions before\u00a0theirs.</li>\n<li>Always run sample code and read it before trying to figure out the solution yourself. L<strong>ook at every\u00a0file!</strong>\n</li>\n<li>If it is working with sample code, it should work with your code as\u00a0well.</li>\n<li>Rather than looking for answers over Google, try to look for other people\u2019s code and see why their code is working. Point number 3 goes with this as\u00a0well.</li>\n<li>The problem might not be in the code, system settings can be\u00a0false.</li>\n<li>Pay a closer look at what is going on, even if you do not understand it in the beginning, you will be able to do that in a\u00a0while.</li>\n<li>Improve your debugging skills and be\u00a0patient.</li>\n<li>Elimination is one of the most helpful debugging techniques.</li>\n</ol>\n<p>Now lets talk about the issues. The very first error that we got\u00a0was:</p>\n<pre>Android Studio \u2014 Unrecognized VM option \u2018MaxPermSize=256m\u2019</pre>\n<p>This is a very known problem with many different answers to the questions. One most obvious answer\u00a0was</p>\n<pre>cd android<br>./gradlew clean<br>react-native run-android</pre>\n<p>What it does is it resets everything and builds the Gradle from scratch. This comes with different variations. Some say to remove\u00a0.gradle and\u00a0.build folders as well. This was a solution to many others but it was not the case with us as we were wrongly doing one very basic step. Another answer that we commonly found\u00a0was:</p>\n<p>\u201c Open the gradle.properties file and remove MaxPremSize as this is not compatible with the latest\u00a0JDK.\u201d</p>\n<p>Now, this partially resolved the issue but created another\u00a0one.</p>\n<pre>Task :expo-modules-core:compileDebugKotlin FAILED react native</pre>\n<p>Many answers to this as well but the most common were to clean the build or to update the <em>android/build.gradle</em> file.</p>\n<blockquote>My thoughts are this is a versioning issue. I solved this by changing the versions of buildTools, compileSdk and targetSdk.</blockquote>\n<blockquote>Go to your android/build.gradle file and change the following values:</blockquote>\n<blockquote>buildToolsVersion = \"29.0.3\" to buildToolsVersion =\u00a0\"30.0.0\"</blockquote>\n<blockquote>compileSdkVersion = 29 to compileSdkVersion =\u00a030</blockquote>\n<blockquote>targetSdkVersion = 29 to targetSdkVersion =\u00a030</blockquote>\n<p>Above is one of the most liked answers I found on StackOverflow.</p>\n<p>None of these solutions worked and finally, I decided to read the <em>documentation</em>. <a href=\"https://reactnative.dev/docs/0.64/environment-setup\">There</a>, I saw that React Native requires the Android 10 (Q) SDK in particular with buildToolsVersion = \"29.0.2\". Moreover, it requires JDK version 11. I grabbed my head in despair and laughed at my stupidity. I looked at my system settings and found that I was using JDK 17 along with SDK 31.0.0. This covers my points 1,3 and 5. <strong>The community was saying there is no need to downgrade, but it only worked once that was\u00a0done.</strong></p>\n<p>So far I had not used sample codes, but soon that was about to change. Once I was done with this, I got stuck into another\u00a0problem.</p>\n<pre>Execution failed for task ':app:compileDebugJavaWithJavac'. react-native.</pre>\n<p>Now what was that all about? I was confused and Googled the query. The same cleaning answer topped the chart again along with some other hacks for\u00a0example:</p>\n<blockquote>So, inspect you node_modules folder, look for react-native folder and look for a folder with a number, that numbers are react-native version. For me it\u2019s 0.58.3 then update <strong>android/app/build.gradle</strong>:</blockquote>\n<blockquote>implementation \"com.facebook.react:react-native:0.58.3\"</blockquote>\n<p>What it means is that we have to specify the exact react-native version to get it working. For me, that was not the\u00a0case.</p>\n<p>I took a step back and downloaded the sample code. I tried running it and it worked how it should. There were no issues at all. That proved that my system has accurate settings and is ready to go. I looked at other people's codes and they were working fine as well. I saw their Gradle files and found no difference there as well. So what does that mean? There is some issue with just my\u00a0code.</p>\n<p>Upon looking at the logs again, I saw that the issue was in generated:</p>\n<pre>android/app/build/generated/rncli/src/main/java/com/facebook/react/PackageList.java</pre>\n<p>This file creates a list of all imports that are required to run the application. The problem was that there were two imports with the same name. In my case it\u00a0was</p>\n<pre>import <em>com.reactnativecommunity.cookies.CookieManagerPackage</em>;</pre>\n<p>Why was that happening, I did not know at that time. But this was the only culprit to be seen. So I started eliminating every package from package.json the file. At last, I found the issue. There were two imports in the JSON\u00a0file</p>\n<pre>react-native-cookies/cookies<br>@react-native-cookies/cookies</pre>\n<p>Now both of them were trying to import CookieManagerPackage and hence Java was not able to compile the code. This was not an issue with iOS and we assumed that this will not cause an issue with Android as\u00a0well.</p>\n<p>Once this was done, our application was running on Emulator just fine. The last issue was when we tried to make the release. The community said there is no need to sign the Android APK for debugging, but that was not the case. Even if you are not releasing it on App Store, you will have to sign it to run it on a real device. Follow the steps\u00a0here:</p>\n<p><a href=\"https://reactnative.dev/docs/signed-apk-android\">Publishing to Google Play Store \u00b7 React Native</a></p>\n<p>This takes us to points 2, 4, 6, 7, 8. Before going for the blind search on Google, you should try to read the documentation and other code examples. Usually, the answers are closer than we think. Also, if the documentation is giving instructions, follow that before following other people\u2019s opinions. They might be using a hack that does not work for everyone.</p>\n<p>I found a very nice meme that summarizes our actions as developers on the daily\u00a0basis.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*F0fV-wyPtO2RP1O374zipA.png\"></figure><p>In the end, I would just like to emphasize the importance of reading documentation and developing strong debugging skills. This article can be used as a guide to run Android Applications on emulators or to create a build when working with React\u00a0Native.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=10e34ef52eb0\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["java","emulator","react-native","bugs","android"]},{"title":"A better alternative of `as` in Typescript","pubDate":"2021-11-23 05:08:24","link":"https://medium.com/@faizan-ali/a-better-alternative-of-as-in-typescript-3eadc4afc633?source=rss-694dc83417cb------2","guid":"https://medium.com/p/3eadc4afc633","author":"Faizan Safdar Ali","thumbnail":"https://cdn-images-1.medium.com/max/1024/1*Sdr6VWtJnnrN97Fu8s-dqw.png","description":"\n<p>An alarm has been raised for the Typescript developers, who seek the safe heavens under the keyword \u2018as\u2019 for typecasting, that Typescript might be removing this privilege in the upcoming\u00a0updates.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Sdr6VWtJnnrN97Fu8s-dqw.png\"></figure><p>\u201cas\u201d keyword is a <a href=\"https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#type-assertions\">Type Assertion in TypeScript</a> which tells the compiler to consider the object as another type than the type the compiler infers the object to be. According to the documentation:</p>\n<blockquote>\u201cSometimes you will have information about the type of a value that TypeScript can\u2019t know\u00a0about.</blockquote>\n<blockquote>For example, if you\u2019re using document.getElementById, TypeScript only knows that this will return <em>some</em> kind of HTMLElement, but you might know that your page will always have an HTMLCanvasElement with a given\u00a0ID.\u201d</blockquote>\n<p>Can you see the problem over\u00a0here?</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/298/0*GDDUn8jCQnD3X9wj.gif\"></figure><p>There are actually\u00a0two:</p>\n<ol>\n<li>What if HTMLCanvasElement is not returned by document.getElementById\u00a0? This may happen because of a regression. In this case, the compiler will never raise any issue but your code will break on run time because of `TypeMismatchException:Failed to convert the value of\u00a0type\u2026`.</li>\n<li>What if can return HTMLCanvasElement along with another HTMLElement\u00a0? This can also happen then you are expecting another element instead of HTMLCanvasElement.</li>\n</ol>\n<p>In both above cases, \u201cas\u201d is not <em>AS </em>effective as one might think. There is a high chance that you leave a bug in the\u00a0code.</p>\n<p>So what is going to be our superhero over\u00a0here?</p>\n<p>Comes the \u201cin\u201d\u00a0keyword.</p>\n<p>Let's look at the following code\u00a0snippet.</p>\n<pre>interface A {<br>  x: number;<br>}<br>interface B {<br>  y: string;<br>}<br><br>let q: A | B = ...;<br>if ('x' in q) {<br>  ... some code</pre>\n<pre>someFunc(q as A)<br>} else {<br>  ... some code</pre>\n<pre>  anotherFunc(q as B)<br>}</pre>\n<p>What\u2019s happening over here is that we have two interfaces A and B. Now variable \u2018q\u2019 can be either of them. Based on its type, we are either calling someFunc or anotherFunc. As we can see the important part here is that both functions are expecting a specific type as an input. Also, there are some operations being done based on the type of\u00a0\u201cq\u201d.</p>\n<p>In the above scenario, the \u201cas\u201d keyword would definitely fail as we do not know what type of data is coming in. Instead \u201cin\u201d can define the type of \u201cq\u201d with\u00a0surety.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/480/0*o45DhFFgi5tlDc6B.gif\"></figure><p>In summary, we should try avoiding the usage of the \u201cas\u201d keyword because that can lead to runtime errors. Instead \u201cin\u201d is a much better\u00a0option.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3eadc4afc633\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>An alarm has been raised for the Typescript developers, who seek the safe heavens under the keyword \u2018as\u2019 for typecasting, that Typescript might be removing this privilege in the upcoming\u00a0updates.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*Sdr6VWtJnnrN97Fu8s-dqw.png\"></figure><p>\u201cas\u201d keyword is a <a href=\"https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#type-assertions\">Type Assertion in TypeScript</a> which tells the compiler to consider the object as another type than the type the compiler infers the object to be. According to the documentation:</p>\n<blockquote>\u201cSometimes you will have information about the type of a value that TypeScript can\u2019t know\u00a0about.</blockquote>\n<blockquote>For example, if you\u2019re using document.getElementById, TypeScript only knows that this will return <em>some</em> kind of HTMLElement, but you might know that your page will always have an HTMLCanvasElement with a given\u00a0ID.\u201d</blockquote>\n<p>Can you see the problem over\u00a0here?</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/298/0*GDDUn8jCQnD3X9wj.gif\"></figure><p>There are actually\u00a0two:</p>\n<ol>\n<li>What if HTMLCanvasElement is not returned by document.getElementById\u00a0? This may happen because of a regression. In this case, the compiler will never raise any issue but your code will break on run time because of `TypeMismatchException:Failed to convert the value of\u00a0type\u2026`.</li>\n<li>What if can return HTMLCanvasElement along with another HTMLElement\u00a0? This can also happen then you are expecting another element instead of HTMLCanvasElement.</li>\n</ol>\n<p>In both above cases, \u201cas\u201d is not <em>AS </em>effective as one might think. There is a high chance that you leave a bug in the\u00a0code.</p>\n<p>So what is going to be our superhero over\u00a0here?</p>\n<p>Comes the \u201cin\u201d\u00a0keyword.</p>\n<p>Let's look at the following code\u00a0snippet.</p>\n<pre>interface A {<br>  x: number;<br>}<br>interface B {<br>  y: string;<br>}<br><br>let q: A | B = ...;<br>if ('x' in q) {<br>  ... some code</pre>\n<pre>someFunc(q as A)<br>} else {<br>  ... some code</pre>\n<pre>  anotherFunc(q as B)<br>}</pre>\n<p>What\u2019s happening over here is that we have two interfaces A and B. Now variable \u2018q\u2019 can be either of them. Based on its type, we are either calling someFunc or anotherFunc. As we can see the important part here is that both functions are expecting a specific type as an input. Also, there are some operations being done based on the type of\u00a0\u201cq\u201d.</p>\n<p>In the above scenario, the \u201cas\u201d keyword would definitely fail as we do not know what type of data is coming in. Instead \u201cin\u201d can define the type of \u201cq\u201d with\u00a0surety.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/480/0*o45DhFFgi5tlDc6B.gif\"></figure><p>In summary, we should try avoiding the usage of the \u201cas\u201d keyword because that can lead to runtime errors. Instead \u201cin\u201d is a much better\u00a0option.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3eadc4afc633\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["in","type-casting","ases","keywords","typescript"]}]}